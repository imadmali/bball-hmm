---
title: "Tagging Basketball Plays with HMM"
author: "Imad Ali"
date: "8/5/2019"
output: 
  html_document:
    toc: true
    toc_depth: 4
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(rstan)
library(bayesplot)
rstan_options(auto_write = TRUE)
```

## Introduction

This case study shows how we can use Bayesian Hidden Markov Models (HMMs) in Stan to extract useful information from basketball player tracking data. Specifically we show how to tag drive events and how to determine defensive assignment. The approach taken here is semisupervised since we know the outcome variables, but do not know the hidden states.

Before diving into basketball data we show how to fit a HMM in Stan using a simple example. This should help build some intution for those who are unfamiliar wit HMMs and will also show how to specify a HMM in the Stan language. 


## Simple HMM Example

HMMs enable you to model a series of observed values. Each observed value maps to a state value, so you also have a series of states that corresponds to the series of observed values. Often the states are hidden so the goal of the model is to,

1. Estimate the parameters that allow you to transition from one state to the next and, given the state, the parameters involved in generating the observation.
2. Predict the most likely state sequence based on the observed data and the parameters estimated in (1).

The state series exhibits the Markov property so the value of the state at time $t$ only depends on the value of the state at time $t-1$.

The plot below illustrates a HMM with one observed outcome generated from the normal distribution and two states. For each time step we have one of the two states along with an observed value. In more complicated data you could have multiple observations and many more states at each time step.

In the plot below you can see how state 1 corresponds to smaller values of the outcome while state 2 corresponds to higher values of the outcome, relatively speaking. In most real-word situations you do not know the state value at each time step because it is hidden. So you make an assumption as to how many states there are and fit a model to infer the state values at each time step.

```{r fig.align='center', fig.height=8, fig.width=9}
hmm_data <- readRDS("../data/hmm_example_data.RDS")
z <- hmm_data$z
y <- hmm_data$y
par(mfrow=c(2,1))
plot(hmm_data$z, type="s",
     main = "Latent States",
     ylab = "State Value",
     xlab = "Time",
     ylim = c(0.5,2.5), yaxt = "n")
axis(2, 1:2, 1:2)
plot(hmm_data$y, type = "l",
     main = "Observed Output",
     ylab = "Observation Value",
     xlab = "Time")
y_plt <- hmm_data$y
y_plt[hmm_data$z==1] <- NA
lines(y_plt, lwd = 3)
legend("bottomright", c("State 1","State 2"), lty = c(1,1), lwd = c(1,3), cex = 0.8)
```

Below is a representation of the HMM that generated the data above. We assume that the outcome variable is generated by the normal distribution. We also assume that we do not know the value of the states over time (so they are truly hidden) but know that there are 2 states. The parameters that we want to estimate in this model are the transition probabilities and the emission probabilities.

* **Transition probabilities** govern how likely it is to move from one state to another or to stay within the same state. This is represented as a matrix.
* **Emission probabilities** govern how likely the outcome was generated by that state.

We can interpret an element in the transition matrix as the probability of going from the row state to the column state. So the diagonal elements give the probability of staying in the same state from time $t-1$ to time $t$ and the off-diagonal elements give the probability of transitioning from one state to the next. Note that each row of the matrix sums to 1. Given our example we have,

* $\theta_{1,1}$: the probability of going from state $k=1$ to state $k=1$.
* $\theta_{2,2}$: the probability of going from state $k=2$ to state $k=2$.
* $\theta_{1,2}$: the probability of going from state $k=1$ to state $k=2$.
* $\theta_{2,1}$: the probability of going from state $k=2$ to state $k=1$.

Since the data in this example are normally distributed the emission probabilities come from the normal distribution. The emission probabilities depend on the location and scale parameter associated with each state (i.e. emission parameters). In our example we assume the scale parameter is known and only have to estimate the location parameters for each state.

In order to estimate the parameters we need define the posterior distribution which requires us to specify the likelihood of the data and the priors. The likelihood is defined by the probability of observing that particular sequence of outcome variables. The priors are defined on the transition matrix and on the emission parameters. Since each row of the transition matrix sums to 1, a natural prior distribution choice is to define the Dirichlet distribution on each row of the matrix. Using the likelihood and the priors we can estimate the transition matrix and the emission parameters using the [forward algorithm](https://en.wikipedia.org/wiki/Forward_algorithm).

Once we estimate the parameters we can determine the most probable state sequence than generated the sequence of observations. This can be achived with the [Viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm).

### Specifying the Model

Below we represent the model above in the Stan modeling language. The `model {}` block specifies the priors and the forward algorithm to determine the most likely state at each point in time, and the `generated quantities {}` block specifies the Viterbi algorithm to enable us to determine the most likely state sequence.

```{stan eval=FALSE, output.var='hmm_example'}
data {
  int<lower=0> N;
  int<lower=0> K;
  real y[N];
}

parameters {
  simplex[K] theta[K];
  // real psi[K];
  positive_ordered[K] psi;
}

model {
  // priors
  target+= normal_lpdf(psi[1] | 3, 1);
  target+= normal_lpdf(psi[2] | 10, 1);
  // forward algorithm
  {
  real acc[K];
  real gamma[N, K];
  for (k in 1:K)
    // gamma[1, k] = log(phi[k, u[1]]);
    gamma[1, k] = normal_lpdf(y[1] | psi[k], 1);
  for (t in 2:N) {
    for (k in 1:K) {
      for (j in 1:K)
        // acc[j] = gamma[t-1, j] + log(theta[j, k]) + log(phi[k, u[t]]);
        acc[j] = gamma[t-1, j] + log(theta[j, k]) + normal_lpdf(y[t] | psi[k], 1);
      gamma[t, k] = log_sum_exp(acc);
    }
  }
  target += log_sum_exp(gamma[N]);
  }
}

generated quantities {
  int<lower=1,upper=K> y_star[N];
  real log_p_y_star;
  {
    int back_ptr[N, K];
    real best_logp[N, K];
    real best_total_logp;
    for (k in 1:K)
      // best_logp[1, k] = log(phi[k, u[1]]);
      best_logp[1, k] = normal_lpdf(y[1] | psi[k], 1);
    for (t in 2:N) {
      for (k in 1:K) {
        best_logp[t, k] = negative_infinity();
        for (j in 1:K) {
          real logp;
          // logp = best_logp[t-1, j] + log(theta[j, k]) + log(phi[k, u[t]]);
          logp = best_logp[t-1, j] + log(theta[j, k]) + normal_lpdf(y[t] | psi[k], 1);
          if (logp > best_logp[t, k]) {
            back_ptr[t, k] = j;
            best_logp[t, k] = logp;
          }
        }
      }
    }
    log_p_y_star = max(best_logp[N]);
    for (k in 1:K)
      if (best_logp[N, k] == log_p_y_star)
        y_star[N] = k;
    for (t in 1:(N - 1))
      y_star[N - t] = back_ptr[N - t + 1, y_star[N - t + 1]];
  }
}
```

### Fit the Model

```{r results='hide'}
stan_data <- list(N = length(hmm_data$y),
                  K = 2,
                  y = hmm_data$y)
hmm_fit <- stan("../models/hmm_example.stan", data = stan_data, iter = 1e3, chains = 4)
```

### Post-estimation Validation

The post estimation steps that we take to validate are,

1. Diagnostics - Make sure that each parameter sample converged. This can be evaluated by examining the traceplots and the R-hat values for each parameter.
2. Predictions - Specifically we perform a posterior predictive check. Using the estimated parameters and the predicted state sequence we can predict multiple output sequences and see if they line up with the observed output sequence. Additionally, since we know the true state values, we can check to make sure the predicted state values line up the true state values.

#### Diagnostics

```{r}
samples <- as.matrix(hmm_fit)

psi_indx <- grep("^psi\\[", colnames(samples))
theta_indx <- grep("^theta\\[", colnames(samples))
y_star_indx <- grep("^y_star\\[", colnames(samples))

colMeans(samples[,theta_indx])
colMeans(samples[,psi_indx])

```

```{r fig.align='center', fig.width=6, fig.height=6}
mcmc_trace(as.array(hmm_fit), regex_pars = "^theta\\[")
```

```{r fig.align='center', fig.width=6, fig.height=3}
mcmc_trace(as.array(hmm_fit), regex_pars = "^psi\\[")
```

#### Predictions

Below we plot 100 outcome sequences given the predicted states and parameter estimates. Notice how the predictions line up nicely with the observed output values. This indicates that the data generation process was appropriately modeled.

```{r}
# fixme!
```

Below we plot the predicted states of the true states and come to a similar conclusion.

```{r fig.align='center', fig.width=8, fig.height=9}
y_star <- colMeans(samples[,y_star_indx])
# visualization
par(mfrow=c(2,1))
plot(hmm_data$z, type="s",
     main = "Latent States",
     ylab = "State Value",
     xlab = "Time",
     ylim = c(0.5,2.5), yaxt = "n")
axis(2, 1:2, 1:2)
points(y_star, cex = 0.5)
legend("bottomright", c("Actual","Predicted"), pch = c(NA,1), lty = c(1,NA), cex = 0.8)
plot(hmm_data$y, type = "l",
     main = "Observed Output",
     ylab = "Observation Value",
     xlab = "Time")
y_plt <- hmm_data$y
y_plt[hmm_data$z==1] <- NA
lines(y_plt, lwd = 3)
legend("bottomright", c("State 1","State 2"), lty = c(1,1), lwd = c(1,3), cex = 0.8)
```

## Tag Drive Events

The goal here is to apply the methodology above to tag a drive in basketball. A drive occurs when a player dribbles the ball towards the hoop for a layup. We can translate a drive into two types of events that are happening over time until the layup is attempted,

* The player increases their speed.
* The player reduces the distance between himself and the basket.

The video below illustrates what a drive event looks like in the player tracking data. This drive possession was attributed to Zach LaVine in a Minnesota Timberwolves v Boston Celtics game (12/21/2015).

### Pre-process Data

Using the player tracking data we can construct metrics associated with our time series events. We define speed as distance over time and use  Euclidean distance to determine the player's distance from the hoop at each time step. Below is an illustration of Zach LaVine's distance from basket and speed metrics. Consistent with our interpretation of drive, notice how he decreases his distance from the basket as he increases his speed.

```{r fig.align='center', fig.height=8, fig.width=9}
drive_data <- readRDS("../data/evt140_0021500411.RDS")
par(mfrow = c(2,1))
plot(drive_data$game$lavine_dist, type = "l",
     xlab = "Time (25hz)", ylab = "Distance from Hoop")
plot(drive_data$game$lavine_speed, type = "l",
     xlab = "Time (25hz)", ylab = "Speed")
```

The speed metric is pretty noisy. This may be attributed to the fact that time is measured in 25 hertz (25ths of a second) and that location is determined by a computer vision algorithm and not a tracking chip attached to the player. They are many methods that can be used to smooth the data (e.g. splines). Here we use a basic rolling mean with a window of three time steps. In our example the data is not so noisy that it would affect the performance of our model so the smoothing is mostly for aesthetics and ease of interpretation. If the variance in the series was more extreme then we might want consider implementing a better smoothing method before fitting our model.

```{r fig.align='center', fig.height=8, fig.width=9}

lavine_speed_smooth <- rep(drive_data$game$lavine_speed[2],2)
for (i in 3:nrow(drive_data$game))
  lavine_speed_smooth[i] <- mean(drive_data$game$lavine_speed[(i-2):i], na.rm=TRUE)

drive_data <- readRDS("../data/evt140_0021500411.RDS")
par(mfrow = c(2,1))
plot(drive_data$game$lavine_speed, type = "l",
     main = "Raw Speed",
     xlab = "Time (25hz)", ylab = "Speed")
plot(lavine_speed_smooth, type = "l",
     main = "Smooth Speed",
     xlab = "Time (25hz)", ylab = "Speed")
```

Now that we have the data we can specify and fit the model.

### Specifying and Fitting the Model

Below is an graphic representation of the process that we are trying to model. 

```{stan eval=FALSE, output.var='drive_model.stan'}
data {

}
parameters {

}
model {

}
```

Below we fit the model to LaVine's data for the single drive event and inspect the traceplot of the parameter chains as a basic diagnostic check.

### Post-processing Data

We post-process the state predictions and layer them on top of the original distance/speed plots to see if the predictions lined up with our logic.

We can also layer the predicted latent states on top of the previous video for a more comprehensive view. 

It looks like things line up nicely. The drive event gets triggered only when the player dramatically reduces their distance from the basket and increases their speed over time and

## Defensive Assignment

Our final task is to determine defensive assignment in basketball using HMMs. We follow an approach similar to Franks et al (2015). However, instead of fitting the HMM using the E-M algorithm we fit the model in Stan. Before diving into the model we need to abstract what good basketball defense is, mathematically speaking. Arguably, good defensive positioning means that the defender is somehwere in the triangle defined by the location of the hoop, the ball, and the offensive player in question. An example of this is illustrated below.

```{r fig.align='center', fig.width=5, fig.height=3}
h <- c(0,-1)
b <- c(0,1.5)
o <- c(-1,0.5)
d <- c(-0.3,0.3)
plot(rbind(h,b,o,h), type = "o",
     xlim = c(-2,1), ylim = c(-2,2),
     xlab = "", ylab = "", xaxt = "n", yaxt = "n",
     pch = 20)
points(d[1],d[2], pch = 20)
text(h[1],h[2], "hoop", pos = 1)
text(b[1],b[2], "ball", pos = 3)
text(o[1],o[2], "offensive player", pos = 2)
text(d[1],d[2], "defender", pos = 3)
```

Using this concept, we model the defender's position as 2 draws from the normal distribution where the location parameter is defined as a convex combination of the hoop, ball, and offensive player. Mathematically we can represent this for each time step as,

$$
y_{1}, y_{2} \sim \mathcal{N}(\mu_{k}, \sigma^{2}) \\
\mu_{k} = O_{k}\lambda_{1} + B\lambda_{2} + H\lambda_{3}
$$
where, at each time step, $O_{k}$ is the position of the kth offensive player, $B$ is the position of the ball, and $H$ is the position of the hoop. Because $\mu_{k}$ is a convex combination we also have the following constraint,

$$
\lambda_{1} + B\lambda_{2} + H\lambda_{3} = 1 \\
\Leftrightarrow \\
\Lambda \mathbf{1} = 1
$$

Defining the model with the state process $z_t$ and the time steps gives the following,

$$
z_{t} \sim \mbox{Categorical}(\theta_{z_{t-1}}) \\
y_{t1}, y_{t2} \sim \mathcal{N}(\mu_{z_{t}}, \sigma^{2}) \\
\mu_{z_{t}} = O_{z_{t}}\lambda_{1} + B\lambda_{2} + H\lambda_{3} \\
\Lambda \mathbf{1} = 1
$$

For a single defender, this model determines which one of the five offensive players is being guarded at each time step.

Below is a graphical representation of the model when considering a single defender.

In stan we can represent the model as follows.

### Fake Data

Before applying the model directly to the player tracking data we should check to see if our model performs appropriately with simulated data. Working in this type of controlled situation will also shed some intuition on what the model is doing. 

The code [here]() simulates an overly simplified basketball possession. For 20 time steps we sample a fixed position of five offensive players (`o1` to `o5`) and the ball. (We do this with trivial noise to mimic the player tracking data.) We include the hoop location as a single coordinate as the position is fixed over time. With all these pieces in place we trace the path of a single defender in a parabola shape around the hoop.

```{r fig.align='center', fig.width=4, fig.height=4}
defense_example <- readRDS("../data/defense_example.RDS") 
list2env(defense_example, .GlobalEnv)
# plot
plt_defense_example(defense_example, main = "Defense Example")
points(d[,1], d[,2], col = "#ff6688", pch = 0)
```

Intuitively we want the model to say that the defender is guarding a particular offensive player if the defender is closest to the convex combination generated by that offensive player.

Below we fit the model to fake data assuming that the convex combination parameters are known and fixed to $\Gamma = [1/3,1/3,1/3]$. This approach strongly biases the model to prior knowledge about where defenders are situated when guarding offensive players. Specifically it states that location (hoop, ball, and offensive player) is weighted equally in the convex combination so that the defensive player's location does not favor one position over the other.

```{r}
defense_example$lambda <- c(1/3,1/3,1/3)  # fixing convex combination parameter
defense_0a_fit <- stan("../models/defense_0a.stan", data = defense_example, chains = 4, iter = 1e3)
```

The model below assumes that $\Gamma$ is not known and has to be estimated from the data. We can still incorporate prior information about defensive positioning by applying the appropriate prior distribution on $\Gamma$. However, this will be less strict compared to declaring $\Gamma$ explicitly. This approach lets us learn about $\Gamma$ from the data. This means that we can compute which positioning defenders favor when in the convex combination (i.e. to they tend to be closer to the ball, hoop, or offensive player).

```{r eval=FALSE}
defense_example$alpha <- c(3,3,3)  # priors on convex combination parameter
defense_0b_fit <- stan("../models/defense_0b.stan", data = defense_example, chains = 4, iter = 1e3)
```

For each model we plot the states associated with each position for the defender (these correspond to the offensive player numbers). Additionally, we plot the convex combination $\mu_k$ for each offensive player. You can see how defensive assignment is related to how close the defender is to $\mu_k$. In this example the difference between fixing and estimating $\Lambda$ is apparent. When we estimate $\Lambda$ the defender favors positioning themselves closer to the offensive player and hoop rather than the ball (this is reflected in larger values of $\lambda$ for the offensive player and ball). 

```{r fig.align='center', fig.width=8,fig.height=4}
samples_0a <- as.matrix(defense_0a_fit)
samples_0b <- as.matrix(defense_0b_fit)
y_star_0a <- samples[,grep("^y_star", colnames(samples_0a))]
y_star_0b <- samples[,grep("^y_star", colnames(samples_0b))]
y_star_0a <- colMeans(y_star_0a)
y_star_0b <- colMeans(y_star_0b)

lambda <- samples[,grep("^lambda", colnames(samples_0b))]
lambda <- colMeans(lambda)

# compute convex combination given fixed lambda
mu_0a <- list(mu1 = t(rbind(o[1,1,],h,b[1,])) %*% c(1/3,1/3,1/3) %>% t %>% c,
              mu2 = t(rbind(o[2,1,],h,b[1,])) %*% c(1/3,1/3,1/3) %>% t %>% c,
              mu3 = t(rbind(o[3,1,],h,b[1,])) %*% c(1/3,1/3,1/3) %>% t %>% c,
              mu4 = t(rbind(o[4,1,],h,b[1,])) %*% c(1/3,1/3,1/3) %>% t %>% c,
              mu5 = t(rbind(o[5,1,],h,b[1,])) %*% c(1/3,1/3,1/3) %>% t %>% c)
# compute convex combination given lambda estimate
mu_0b <- list(mu1 = t(rbind(o[1,1,],h,b[1,])) %*% lambda %>% t %>% c,
              mu2 = t(rbind(o[2,1,],h,b[1,])) %*% lambda %>% t %>% c,
              mu3 = t(rbind(o[3,1,],h,b[1,])) %*% lambda %>% t %>% c,
              mu4 = t(rbind(o[4,1,],h,b[1,])) %*% lambda %>% t %>% c,
              mu5 = t(rbind(o[5,1,],h,b[1,])) %*% lambda %>% t %>% c)

par(mfrow = c(1,2))
# model defense_0a
plt_defense_example(defense_example, main = expression(paste("Defense Example: ", Lambda, " Fixed")))
lambda_0a_txt <- paste(round(c(1/3,1/3,1/3),2), collapse = ",")
text(-2,1.9, bquote(paste(Lambda, " = [", .(lambda_0a_txt),"]")), pos = 4)
text(d[,1], d[,2], labels = paste(y_star), col = "#ff668890")
text(mu_0a$mu1[1], mu_0a$mu1[2], expression(mu[1]), cex = 0.8)
text(mu_0a$mu2[1], mu_0a$mu2[2], expression(mu[2]), cex = 0.8)
text(mu_0a$mu3[1], mu_0a$mu3[2], expression(mu[3]), cex = 0.8)
text(mu_0a$mu4[1], mu_0a$mu4[2], expression(mu[4]), cex = 0.8)
text(mu_0a$mu5[1], mu_0a$mu5[2], expression(mu[5]), cex = 0.8)
# model defense_0b
plt_defense_example(defense_example, main = expression(paste("Defense Example: ", Lambda, " Estimated")))
lambda_0b_txt <- sprintf("%.2f", round(lambda,2), collapse=",")
lambda_0b_txt <- paste(lambda_0b_txt, collapse = ",")
text(-2,1.9, bquote(paste(Lambda %~~% phantom(), "[", .(lambda_0b_txt),"]")), pos = 4)
text(d[,1], d[,2], labels = paste(y_star), col = "#ff668890")
text(mu_0b$mu1[1], mu_0b$mu1[2], expression(mu[1]), cex = 0.8)
text(mu_0b$mu2[1], mu_0b$mu2[2], expression(mu[2]), cex = 0.8)
text(mu_0b$mu3[1], mu_0b$mu3[2], expression(mu[3]), cex = 0.8)
text(mu_0b$mu4[1], mu_0b$mu4[2], expression(mu[4]), cex = 0.8)
text(mu_0b$mu5[1], mu_0b$mu5[2], expression(mu[5]), cex = 0.8)
```

### Player Tracking Data

Now that we are confident with our model we can apply it to the player tracking data. We continue with the data from the previous section which is based on a drive possession. This defines an easy to work with possession where the Minnesota Timberwolves are the offensive team and the Boston Celtics are the defensive team.

So far the models in this section have shown how to infer defensive assignment for only one defender. In order to apply this to possesion level player tracking data we need to determine defensive assignment for each of the 5 defenders. We implement this in Stan by adding an extra dimension $D=5$ to the observed data $y$ and wrap the forward algorithm and the Viterbi algorithm in a loop to determine defensive assignment for each of the 5 defenders. Now the dimensions of $y$ are (number of defenders, number of states (offenders), number of time steps, number of coordinates (2)), which translates to (5,5,N,2) where N is defined by the length of the possession.

Below we fit HMM to the player tracking to data.

Finally, we can visualize what defensive assignment looks like when inferred from a HMM.

## Conclusion

Talk about how labeling the data would make the HMM parameters consistent with when the drive actually occurs.
Talk about pairing HMM with computer vision algorithms to apply meta data to the drive event regarding the type of shot (floater, bank, finger-roll, etc).

## References

